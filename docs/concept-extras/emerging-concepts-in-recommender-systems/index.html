<!doctype html>
<html class="docs-version-current" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.14">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Recohut RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Recohut Atom Feed">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><title data-react-helmet="true">Emerging Concepts in Recommender Systems | Recohut</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://docs.recohut.com/docs/concept-extras/emerging-concepts-in-recommender-systems"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="Emerging Concepts in Recommender Systems | Recohut"><meta data-react-helmet="true" name="description" content="Real-time Learning and Inference"><meta data-react-helmet="true" property="og:description" content="Real-time Learning and Inference"><link data-react-helmet="true" rel="icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://docs.recohut.com/docs/concept-extras/emerging-concepts-in-recommender-systems"><link data-react-helmet="true" rel="alternate" href="https://docs.recohut.com/docs/concept-extras/emerging-concepts-in-recommender-systems" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://docs.recohut.com/docs/concept-extras/emerging-concepts-in-recommender-systems" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.52d28afd.css">
<link rel="preload" href="/assets/js/runtime~main.cb8160eb.js" as="script">
<link rel="preload" href="/assets/js/main.fedda83c.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_OuoZ">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Recohut Logo" class="themedImage_TMUO themedImage--light_4Vu1"><img src="/img/logo.svg" alt="Recohut Logo" class="themedImage_TMUO themedImage--dark_uzRr"></div><b class="navbar__title">Recohut</b></a><a class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/recohut/docs" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_iYfV toggle_2i4l toggleDisabled_xj38"><div class="toggleTrack_t-f2" role="button" tabindex="-1"><div class="toggleTrackCheck_mk7D"><span class="toggleIcon_pHJ9">üåú</span></div><div class="toggleTrackX_dm8H"><span class="toggleIcon_pHJ9">üåû</span></div><div class="toggleTrackThumb_W6To"></div></div><input type="checkbox" class="toggleScreenReader_h9qa" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_lDyR"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_i9tI" type="button"></button><aside class="docSidebarContainer_0YBq"><div class="sidebar_a3j0"><nav class="menu thin-scrollbar menu_cyFh"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link hasHref_TwRn" href="/docs/concept-basics/">Concept - Basics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Concept - Basics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--active hasHref_TwRn" href="/docs/concept-extras/">Concept - Extras</a><button aria-label="Toggle the collapsible sidebar category &#x27;Concept - Extras&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/concept-extras/amazon-personalize">Amazon Personalize</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/concept-extras/apps">Apps</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/concept-extras/bias-&amp;-fairness">Bias &amp; Fairness</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/concept-extras/causal-inference">Causal Inference</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/concept-extras/cold-start">Cold Start</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/concept-extras/cross-domain">Cross-domain</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/concept-extras/data-science">Data Science</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/concept-extras/diversity">Diversity</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/concept-extras/emerging-concepts-in-recommender-systems">Emerging Concepts in Recommender Systems</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/concept-extras/graph-embeddings">Graph Embeddings</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/concept-extras/graph-networks">Graph Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/concept-extras/incremental-learning">Incremental Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/concept-extras/jensen-shannon-divergence">Jensen‚ÄìShannon divergence</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/concept-extras/meta-learning">Meta Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/concept-extras/mlops">MLOps</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/concept-extras/model-deployment">Model Deployment</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/concept-extras/model-retraining">Model Retraining</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/concept-extras/multi-objective-optimization">Multi-Objective Optimization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/concept-extras/multi-task-learning">Multi-Task Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/concept-extras/multitask-learning">Multi-task Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/concept-extras/offline-learning">Off-Policy Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/concept-extras/scalarization">Scalarization</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_TwRn" tabindex="0" href="/docs/concept-extras/nlp/chatbot">NLP</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_TwRn" tabindex="0" href="/docs/concept-extras/success-stories/1mg-prod2vec">Success Stories</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_TwRn" tabindex="0" href="/docs/concept-extras/vision/facial-analytics">Computer Vision</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link hasHref_TwRn" href="/docs/models/">Models</a><button aria-label="Toggle the collapsible sidebar category &#x27;Models&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link hasHref_TwRn" href="/docs/tutorials/">Tutorials</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tutorials&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link hasHref_TwRn" href="/docs/tools/">Tools</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tools&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/datasets">Datasets</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/projects">Projects</a></li></ul></nav></div></aside><main class="docMainContainer_r8cw"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_zHA2"><div class="docItemContainer_oiyr"><article><div class="tocCollapsible_aw-L theme-doc-toc-mobile tocMobile_Tx6Y"><button type="button" class="clean-btn tocCollapsibleButton_zr6a">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Emerging Concepts in Recommender Systems</h1></header><h2 class="anchor anchorWithStickyNavbar_y2LR" id="real-time-learning-and-inference">Real-time Learning and Inference<a class="hash-link" href="#real-time-learning-and-inference" title="Direct link to heading">‚Äã</a></h2><h3 class="anchor anchorWithStickyNavbar_y2LR" id="batch-vs-real-time">Batch vs. Real-time<a class="hash-link" href="#batch-vs-real-time" title="Direct link to heading">‚Äã</a></h3><p>Batch recommendations are computationally cheaper. They are usually generated once a day and benefit from batch processing‚Äôs economies of scale. Batch recommendations are also simpler ops-wise. In contrast, real-time recommendations usually require more computation. For example, we might aggregate streamed events (e.g., click, like, purchase) and generate new recommendations on-demand, based on user interactions. Operating real-time recommendations in production is also far tricker and the ops burden also increases. </p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="why-real-time-recommendations-then"><strong>Why real-time recommendations then?</strong><a class="hash-link" href="#why-real-time-recommendations-then" title="Direct link to heading">‚Äã</a></h3><p>Real-time recommenders are useful when the customer journey is mission-centric and depends on the context. Such missions are often time-sensitive. Real-time demand fades quickly; demand could be met (on a competitor site) or the user might lose interest. For example, real-time recommendations are useful when the majority of our customers are new (i.e., cold-start). This happens when we‚Äôre in the customer acquisition stage, such as when we‚Äôve just launched a new product or entered a new market (e.g., e-commerce in Southeast Asia in 2013 - 2015).</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="example">Example<a class="hash-link" href="#example" title="Direct link to heading">‚Äã</a></h3><p>Imagine you‚Äôve just downloaded an e-commerce app. Since we‚Äôre uncertain of your gender, the home page will have a mix of categories catering to each gender, from dresses to men‚Äôs shirts, from GPUs to makeup. If you click on a dress, we can immediately build a persona (that you‚Äôre female) and personalize your shopping experience. In this case, the u2i recommendations on your home page will tilt towards female products.</p><p>To understand the drawbacks of batch-processed recommendation, imagine that a customer visits your online store, and adds pair of sunglasses to her basket. What does your offline engine typically suggest her to add next? The answer, in most cases, is more sunglasses.Your engine knows customer‚Äôs past purchase but it doesn‚Äôt know what she‚Äôs about to purchase, and it can‚Äôt adjust to accommodate this new knowledge. As a result, its subsequent recommendations will not be interesting, and the customer is likely to ignore them. A better approach would be to react to the customer‚Äôs actions while they are still browsing your site, and recalculate their recommendations in real time, for example, to suggest accessories, pants or shirt to match the new pair of sunglasses. This would give the customer the feel as talking to a sales assistant in-store and make her experience more personalized.</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="industry-examples">Industry examples<a class="hash-link" href="#industry-examples" title="Direct link to heading">‚Äã</a></h3><ul><li><a href="https://102.alibaba.com/detail?id=183" target="_blank" rel="noopener noreferrer">Alibaba</a></li><li><a href="https://dl.acm.org/doi/10.1145/2723372.2742785" target="_blank" rel="noopener noreferrer">Tencent</a></li><li><a href="https://dl.acm.org/doi/10.1145/2959100.2959190" target="_blank" rel="noopener noreferrer">YouTube</a></li><li><a href="https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/" target="_blank" rel="noopener noreferrer">Instagram</a></li><li><a href="https://dl.acm.org/doi/10.1145/2959100.2959174" target="_blank" rel="noopener noreferrer">Netflix</a></li><li><a href="https://newsroom.tiktok.com/en-us/how-tiktok-recommends-videos-for-you" target="_blank" rel="noopener noreferrer">Tiktok</a></li><li><a href="https://youtu.be/WQ520rWgd9A" target="_blank" rel="noopener noreferrer">Weibo</a></li><li><a href="https://logicai.io/blog/building-real-time-recommendations-e-commercie-giant/" target="_blank" rel="noopener noreferrer">Sephora</a></li></ul><h3 class="anchor anchorWithStickyNavbar_y2LR" id="interesting-reads">Interesting reads<a class="hash-link" href="#interesting-reads" title="Direct link to heading">‚Äã</a></h3><ul><li><a href="https://www.amazon.science/publications/temporal-contextual-recommendation-in-real-time" target="_blank" rel="noopener noreferrer">Temporal-contextual recommendation in real-time</a></li></ul><h2 class="anchor anchorWithStickyNavbar_y2LR" id="contextual-bandits">Contextual Bandits<a class="hash-link" href="#contextual-bandits" title="Direct link to heading">‚Äã</a></h2><p>An active area of research is recommender systems that incorporate bandit-based approaches. A bandit algorithm is a form of reinforcement learning (RL) that tries to balance exploration of new possibilities with exploitation of profitable ones already discovered. They have been frequently used as an alternative to static A/B testing: a key advantage is their ability to adapt in real time. This could help to overcome the cold start problem. In fact, bandit algorithms could be used to make real-time selections between several recommender systems based on how users respond to the different recommendations provided by each system. An increasingly important application of bandits is in systems that take into account multiple objectives and metrics related to user satisfaction, and/or multiple stakeholders (a ‚Äúmarketplace‚Äù ‚Äì users, advertisers, platform holders, content owners etc.). For example, in a music content recommender system, an additional objective might be to provide ‚Äúfairness‚Äù for long-tail artists and content by ensuring they receive at least some recommendations.</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="online-learning-with-multi-armed-bandits">Online learning with multi-armed bandits<a class="hash-link" href="#online-learning-with-multi-armed-bandits" title="Direct link to heading">‚Äã</a></h3><p>Why are we even building an n-armed bandit in the first place? Why not just use an A/B/n test? Or maybe get your customer on the phone and ask a question? We have data on what customers buy. So you might own a store that sells perfume or cologne, and you know what people are buying. Here‚Äôs the thing though, <strong>things change</strong>; something might be trendy last week isn‚Äôt popular next. Season‚Äôs shift tastes change, and people change as well. Some people are very open to experience while others aren‚Äôt. Some are open to exploration, while others want the same thing every time.</p><p>In many recommendation domains, such as that of recommending news articles, the cold-start problem is pervasive. New articles and stories appear all the time, and the effectiveness of various algorithms may also vary with time. In such cases, it is crucial for the approach to continuously explore the space of various choices as new data are received. At the same time, the learned data are exploited in order to optimize the payoff in terms of the conversion rate. This type of trade-off between exploration and exploitation is managed with the help of multi-armed bandit algorithms.</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="multi-armed-bandit-algorithms-can"><strong>Multi-armed bandit algorithms can...</strong><a class="hash-link" href="#multi-armed-bandit-algorithms-can" title="Direct link to heading">‚Äã</a></h3><ul><li>recommend products with the highest expected value while still exploring other products.</li><li>do not suffer from the cold-start problem and therefore don‚Äôt require customer preferences or information about products.</li><li>take into account the limitations of how much data you have as well as the cost of gathering data (the opportunity cost of sub-optimal recommendations).</li></ul><h3 class="anchor anchorWithStickyNavbar_y2LR" id="contextual-bandits-1">Contextual bandits<a class="hash-link" href="#contextual-bandits-1" title="Direct link to heading">‚Äã</a></h3><p>The contextual bandit problem is a generalization of the multi-armed bandit that extends the model by making actions conditional on the state of the environment. A common real-world contextual bandit example is a news recommendation system. Given a set of presented news articles, a reward is determined by the click-through behavior of the user. If she clicks on the article, a payout of 1 is incurred and 0 otherwise. Click-through-rate (CRT) is used to determine the selection and placement of ads within the news recommendation application.</p><p>Now suppose rewards are determined by CTR in conjunction with metadata about the user (e.g., age and gender), so recommendations can be further personalized. Take a 65 year old female and an 18 year male for example, both who read news articles from their mobile device. The recommendations for these two users should reflect their contrasting profiles. It wouldn‚Äôt make sense to show ads for retirement plans or mature women clothing stores to the 18 year old male.</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="ab-testing-v-multi-armed-bandits">A/B Testing v. Multi-Armed Bandits<a class="hash-link" href="#ab-testing-v-multi-armed-bandits" title="Direct link to heading">‚Äã</a></h3><p>Experiments based on multi-armed bandits are typically much more efficient than ‚Äúclassical‚Äù A-B experiments based on statistical-hypothesis testing. They‚Äôre just as statistically valid, and in many circumstances they can produce answers far more quickly. They‚Äôre more efficient because they move traffic towards winning variations gradually, instead of forcing you to wait for a ‚Äúfinal answer‚Äù at the end of an experiment. They‚Äôre faster because samples that would have gone to obviously inferior variations can be assigned to potential winners. The extra data collected on the high-performing variations can help separate the ‚Äúgood‚Äù arms from the ‚Äúbest‚Äù ones more quickly.</p><p>Basically, bandits make experiments more efficient, so you can try more of them. You can also allocate a larger fraction of your traffic to your experiments, because traffic will be automatically steered to better performing pages.</p><p><img alt="/img/content-concept-raw-emerging-concepts-in-recommender-systems-untitled.png" src="/assets/images/content-concept-raw-emerging-concepts-in-recommender-systems-untitled-7a3a1e7a6d4b82c7b4777e99ebbdd3f9.png"></p><p>As you can see from the plot above, A/B testing does not adapt throughout the stages of the experiment, since the exploration and exploitation phases are static and distinct, whereas the multi-armed bandit adjusts through simultaneous exploration and exploitation. Furthermore, with multi-armed bandits, less time and resources are allocated to inferior arms/slices. Instead, traffic is gradually allocated to more optimal slices throughout the duration of the experiment. One of the big benefits of bandit testing is that bandits mitigate ‚Äòregret,‚Äô which is basically the lost conversion you experience while exploring a potentially worse variation in a test.</p><p>The key idea is that improvement of the recommender policy is achieved in a trial-and-error fashion by taking user features into account. In general, bandit algorithms can be thought of as ‚Äúonline self-improving A/B testing‚Äù. A somewhat cartoonish way of comparison of the usual A/B testing, standard multi-armed bandit approach (online improvement not taking individual user features into account) and contextual bandit approach (online improvement taking individual user features into account) could be viewed as follows.</p><p><img alt="/img/content-concept-raw-emerging-concepts-in-recommender-systems-untitled-1.png" src="/assets/images/content-concept-raw-emerging-concepts-in-recommender-systems-untitled-1-b501da1f06fb3ff8e44f8d46d5a786e2.png"></p><p>Mathematically the player wishes to minimize the regret: <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>n</mi></msub><mo>:</mo><mo>=</mo><mi>n</mi><msub><mi>Œº</mi><mo>‚àó</mo></msub><mo>‚àí</mo><mi>E</mi><mo stretchy="false">[</mo><msubsup><mo>‚àë</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msub><mi>R</mi><mi>t</mi></msub><mo stretchy="false">]</mo><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">R_n := n \mu_* - E[\sum_{t=1}^n R_t],</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">:=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.1944em"></span><span class="mord mathnormal">n</span><span class="mord"><span class="mord mathnormal">Œº</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1757em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">‚àó</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">‚àí</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.104em;vertical-align:-0.2997em"></span><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="mopen">[</span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">‚àë</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8043em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">]</span><span class="mpunct">,</span></span></span></span></span> where¬†Œº‚àó is the expected reward of the best arm (again, a priori this information is obviously unknown)  and¬†E<!-- -->[‚Ä¶]<!-- --> is the expected value. Given this data and assuming that the distributions¬†Pi are sufficiently nice (e.g. Gaussian), one can efficiently solve this problem by exploring and exploiting the given actions.</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="hands-on">Hands-on<a class="hash-link" href="#hands-on" title="Direct link to heading">‚Äã</a></h3><ul><li>BEARS: Towards an Evaluation Framework for Bandit-based Interactive Recommender Systems [<a href="https://youtu.be/GIH_ArJ-ylk" target="_blank" rel="noopener noreferrer">Video</a>] [<a href="https://gitlab.insight-centre.org/andbar/bears/tree/ee55fc872603efc127966b96373d375c0d9e4474/tutorials/RECSYS2020" target="_blank" rel="noopener noreferrer">GitLab</a>]</li><li>Build a Product Recommender Using Multi-Armed Bandit Algorithms [<a href="https://www.offerzen.com/blog/how-to-build-a-product-recommender-using-multi-armed-bandit-algorithms" target="_blank" rel="noopener noreferrer">Blog</a>] [<a href="https://nbviewer.jupyter.org/gist/sparsh-ai/e591aebd23d4bf8864aa6f93b89fc290" target="_blank" rel="noopener noreferrer">Colab</a>]</li><li>Bandit Algorithms for Website Optimization [<a href="https://learning.oreilly.com/library/view/bandit-algorithms-for/9781449341565/" target="_blank" rel="noopener noreferrer">eBook O&#x27;reilly</a>] [<a href="https://github.com/johnmyleswhite/BanditsBook" target="_blank" rel="noopener noreferrer">GitHub</a>] [<a href="https://nbviewer.jupyter.org/gist/sparsh-ai/b42056d45ca8238fe912baad036597a8" target="_blank" rel="noopener noreferrer">Colab</a>]</li></ul><h2 class="anchor anchorWithStickyNavbar_y2LR" id="graphs-networks-and-embeddings">Graphs Networks and Embeddings<a class="hash-link" href="#graphs-networks-and-embeddings" title="Direct link to heading">‚Äã</a></h2><p>In recommender systems, most information has a graph structure. For example, the social relationships among users and knowledge graphs related to items are naturally graph data. In addition, the interactions between users and items can be considered as the bipartite graph, and the item transitions in sequences can be constructed as graphs as well. Therefore, graph learning approaches have been leveraged to get user/item embeddings. Among graph learning methods, graph neural network (GNN) enjoys a massive hype at the moment.</p><p><img alt="/img/content-concept-raw-emerging-concepts-in-recommender-systems-untitled-2.png" src="/assets/images/content-concept-raw-emerging-concepts-in-recommender-systems-untitled-2-3d9fccf2640194132506f879d48de40c.png"></p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="graph-neural-networks">Graph Neural Networks<a class="hash-link" href="#graph-neural-networks" title="Direct link to heading">‚Äã</a></h3><p>GNN models exploit graph structure to guide representation learning. The basic idea is the embedding propagation mechanism, which aggregates the embeddings of neighbors to update the target node‚Äôs embedding. By recursively performing such propagations, the information from multihop neighbors is encoded into the representation of the target node. GNN models have been widely used in many fundamental tasks due to their strong representation ability, spanning from node classification, link prediction, to graph classification, and achieved remarkable improvements.</p><p>Graph neural network is able to capture the higher-order interaction in user-item relationships through iterative propagation. Moreover, if the information of social relationship or knowledge graph is available, it enables to integrate such side information in network structure efficiently.</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="models">Models<a class="hash-link" href="#models" title="Direct link to heading">‚Äã</a></h3><p><img alt="/img/content-concept-raw-emerging-concepts-in-recommender-systems-untitled-3.png" src="/assets/images/content-concept-raw-emerging-concepts-in-recommender-systems-untitled-3-d6dafc51f2a1e916a069075fb08d0f7f.png"></p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="industrial-examples">Industrial examples<a class="hash-link" href="#industrial-examples" title="Direct link to heading">‚Äã</a></h3><p><img alt="/img/content-concept-raw-emerging-concepts-in-recommender-systems-untitled-4.png" src="/assets/images/content-concept-raw-emerging-concepts-in-recommender-systems-untitled-4-67b9c77c059ada439d1801bfd4d99af2.png"></p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="hands-on-1">Hands-on<a class="hash-link" href="#hands-on-1" title="Direct link to heading">‚Äã</a></h3><ul><li>Simple recommender with matrix factorization, graph, and NLP [<a href="https://github.com/eugeneyan/recsys-nlp-graph" target="_blank" rel="noopener noreferrer">Git</a>]</li><li>Application of graph embeddings in recommendation system [<a href="https://github.com/januverma/Graph-Embeddings-Recommendations-DHS2019" target="_blank" rel="noopener noreferrer">Git</a>]</li></ul><h2 class="anchor anchorWithStickyNavbar_y2LR" id="conversational-recommenders">Conversational Recommenders<a class="hash-link" href="#conversational-recommenders" title="Direct link to heading">‚Äã</a></h2><p>Recent years have witnessed the emerging of conversational systems, including both physical devices and mobile-based applications. Both the research community and industry believe that conversational systems will have a major impact on human-computer interaction, and specifically, the RecSys community has begun to explore Conversational Recommendation Systems.</p><p>Conversational recommendation aims at finding or recommending the most relevant information (e.g., web pages, answers, movies, products) for users based on textual- or spoken-dialogs, through which users can communicate with the system more efficiently using natural language conversations. Due to users‚Äô constant need to look for information to support both work and daily life, conversational recommendation system will be one of the key techniques towards an intelligent web. A personalized conversational sales agent could have much commercial potential. E-commerce companies such as Amazon, eBay, JD, Alibaba etc. are piloting such kind of agents with their users.</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="system-designs">System designs<a class="hash-link" href="#system-designs" title="Direct link to heading">‚Äã</a></h3><p><img alt="Typical architecture of a conversational recommender system" src="/assets/images/content-concept-raw-emerging-concepts-in-recommender-systems-untitled-5-713ea13af61354f6ce4074b32f11d32d.png"></p><p>Typical architecture of a conversational recommender system</p><p><img alt="Typical Structure of Task-oriented Dialogue System" src="/assets/images/content-concept-raw-emerging-concepts-in-recommender-systems-untitled-6-f7fe44db61b349a03275df716bc66d45.png"></p><p>Typical Structure of Task-oriented Dialogue System</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="interesting-reads-1">Interesting reads<a class="hash-link" href="#interesting-reads-1" title="Direct link to heading">‚Äã</a></h3><p><a href="http://staff.ustc.edu.cn/~hexn/slides/sigir20-tutorial-CRS-slides.pdf" target="_blank" rel="noopener noreferrer"></a></p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="hands-on-2">Hands-on<a class="hash-link" href="#hands-on-2" title="Direct link to heading">‚Äã</a></h3><ul><li><a href="https://github.com/RUCAIBox/CRSLab" target="_blank" rel="noopener noreferrer">CRSLab is an open-source toolkit for building Conversational Recommender System (CRS)</a></li></ul><h2 class="anchor anchorWithStickyNavbar_y2LR" id="context-aware-recommenders">Context-aware Recommenders<a class="hash-link" href="#context-aware-recommenders" title="Direct link to heading">‚Äã</a></h2><p>The importance of contextual information has been recognized by researchers and practitioners in many disciplines, including e-commerce personalization, information retrieval, ubiquitous and mobile computing, data mining, marketing, and management. While a substantial amount of research has already been performed in the area of recommender systems, many existing approaches focus on recommending the most relevant items to users without taking into account any additional contextual information, such as time, location, or the company of other people (e.g., for watching movies or dining out). There is growing understanding that relevant contextual information does matter in recommender systems and that it is important to take this information into account when providing recommendations.</p><p><img alt="/img/content-concept-raw-emerging-concepts-in-recommender-systems-untitled-7.png" src="/assets/images/content-concept-raw-emerging-concepts-in-recommender-systems-untitled-7-86d81c19a0a5920ef355d1f65a25012a.png"></p><p>Context-aware recommendation systems represent an emerging area of experimentation and research, aiming to provide even more precise content given the context of the user in a particular moment in time. For example, is the user at home, or on the go? Using a larger or smaller screen? Is it morning or night? Given the data available on a certain user, context-aware systems may be able to provide recommendations a user is more likely to take in those scenarios.</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="interesting-hands-on">Interesting hands-on<a class="hash-link" href="#interesting-hands-on" title="Direct link to heading">‚Äã</a></h3><ul><li>Contextual movie recommender [<a href="https://github.com/yadavgaurav251/Context-Aware-Recommender" target="_blank" rel="noopener noreferrer">Git</a>]</li><li>Music recommendation system using Facial Expression and Factorization Machines [<a href="https://github.com/Pager07/Context-aware-music-recommendation-system" target="_blank" rel="noopener noreferrer">Git</a>]</li></ul><p><img alt="/img/content-concept-raw-emerging-concepts-in-recommender-systems-untitled-8.png" src="/assets/images/content-concept-raw-emerging-concepts-in-recommender-systems-untitled-8-00a637c27a682bc0fb87f06cca75fe41.png"></p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="automl-approach-to-recommenders">AutoML approach to Recommenders<a class="hash-link" href="#automl-approach-to-recommenders" title="Direct link to heading">‚Äã</a></h2><p><img alt="/img/content-concept-raw-emerging-concepts-in-recommender-systems-untitled-9.png" src="/assets/images/content-concept-raw-emerging-concepts-in-recommender-systems-untitled-9-3c6b6e5f1329155a4e441c603519e2c2.png"></p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="hands-on-3">Hands-on<a class="hash-link" href="#hands-on-3" title="Direct link to heading">‚Äã</a></h3><ul><li>AutoML: Taking TPOT to the Movies [<a href="https://colab.research.google.com/drive/1nsFIhZ13uOkHjBzv_26IqAHXcfBeB9rV?usp=sharing" target="_blank" rel="noopener noreferrer">Colab</a>]</li></ul><h2 class="anchor anchorWithStickyNavbar_y2LR" id="multi-task-recommenders">Multi-task recommenders<a class="hash-link" href="#multi-task-recommenders" title="Direct link to heading">‚Äã</a></h2><p>In many applications, however, there are multiple rich sources of feedback to draw upon. For example, an e-commerce site may record user visits to product pages (abundant, but relatively low signal), image clicks, adding to cart, and, finally, purchases. It may even record post-purchase signals such as reviews and returns.</p><p>Integrating all these different forms of feedback is critical to building systems that users love to use, and that do not optimize for any one metric at the expense of overall performance.</p><p>In addition, building a joint model for multiple tasks may produce better results than building a number of task-specific models. This is especially true where some data is abundant (for example, clicks), and some data is sparse (purchases, returns, manual reviews). In those scenarios, a joint model may be able to use representations learned from the abundant task to improve its predictions on the sparse task via a phenomenon known as¬†<a href="https://en.wikipedia.org/wiki/Transfer_learning" target="_blank" rel="noopener noreferrer">transfer learning</a>. For example,¬†<a href="https://openreview.net/pdf?id=SJxPVcSonN" target="_blank" rel="noopener noreferrer">this paper</a>¬†shows that a model predicting explicit user ratings from sparse user surveys can be substantially improved by adding an auxiliary task that uses abundant click log data.</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="multi-task-learning">Multi-task learning<a class="hash-link" href="#multi-task-learning" title="Direct link to heading">‚Äã</a></h3><p>Multi-task learning is an approach in which multiple learning tasks are solved at the same time while exploiting commonalities and differences across tasks. It has been used successfully in many computer vision and natural language processing tasks. There are many advantages to using deep neural networks based on multi-task learning. It helps prevent overfitting by generalizing the shared hidden representations. It provides interpretable outputs for explaining the recommendation. It implicitly augments the data and thus alleviates the sparsity problem. Finally, we can deploy multi-task learning for cross-domain recommendations with each specific task generating recommendations for each domain.</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="joint-representation-learning">Joint Representation Learning<a class="hash-link" href="#joint-representation-learning" title="Direct link to heading">‚Äã</a></h3><p>A recent framework called Joint Representation Learning is capable of learning multi-modal representations of users and items. In this framework, each type of information source (review text, product image, numerical rating, etc) is adopted to learn the corresponding user and item representations based on available (deep) representation learning architectures. Representations from different sources are integrated with an extra layer to obtain the joint representations for users and items. In the end, both the per-source and the joint representations are trained as a whole using pair-wise learning to rank for the top-N recommendation. By representing users and items into embeddings offline, and using a simple vector multiplication for ranking score calculation online, JRL also has the advantage of fast online prediction compared with other deep learning approaches to a recommendation that learn a complex prediction network for online calculation. Therefore, another promising research direction is to design better inductive biases in an end-to-end pipeline, which can reason over different modalities data for better recommendation performance.</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="hands-on-4">Hands-on<a class="hash-link" href="#hands-on-4" title="Direct link to heading">‚Äã</a></h3><ul><li>Multi-objective recommender for Movielens [<a href="https://www.tensorflow.org/recommenders/examples/multitask/" target="_blank" rel="noopener noreferrer">Code</a>]</li></ul><h2 class="anchor anchorWithStickyNavbar_y2LR" id="references">References<a class="hash-link" href="#references" title="Direct link to heading">‚Äã</a></h2><table><thead><tr><th>Name</th><th>Link</th></tr></thead><tbody><tr><td>Real-time Machine Learning For Recommendations</td><td><a href="https://eugeneyan.com/writing/real-time-recommendations/" target="_blank" rel="noopener noreferrer">https://eugeneyan.com/writing/real-time-recommendations/</a></td></tr><tr><td>Using Navigation to Improve Recommendations in Real-Time</td><td><a href="https://dl.acm.org/doi/10.1145/2959100.2959174" target="_blank" rel="noopener noreferrer">https://dl.acm.org/doi/10.1145/2959100.2959174</a></td></tr><tr><td>Powered by AI: Instagram&#x27;s Explore recommender system</td><td><a href="https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/" target="_blank" rel="noopener noreferrer">https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/</a></td></tr><tr><td>Deep Neural Networks for YouTube Recommendations</td><td><a href="https://dl.acm.org/doi/10.1145/2959100.2959190" target="_blank" rel="noopener noreferrer">https://dl.acm.org/doi/10.1145/2959100.2959190</a></td></tr><tr><td>TencentRec</td><td>Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data</td></tr><tr><td>Machine learning is going real-time</td><td><a href="https://huyenchip.com/2020/12/27/real-time-machine-learning.html" target="_blank" rel="noopener noreferrer">https://huyenchip.com/2020/12/27/real-time-machine-learning.html</a></td></tr><tr><td><a href="https://www.veed.io/grow/reverse-engineering-how-tiktok-algorithm-works/" target="_blank" rel="noopener noreferrer">https://www.veed.io/grow/reverse-engineering-how-tiktok-algorithm-works/</a></td><td></td></tr><tr><td><a href="http://datasadak.com/what-makes-tiktok-recommendation-system-so-powerful/" target="_blank" rel="noopener noreferrer">http://datasadak.com/what-makes-tiktok-recommendation-system-so-powerful/</a></td><td></td></tr><tr><td><a href="https://newsroom.tiktok.com/en-us/how-tiktok-recommends-videos-for-you" target="_blank" rel="noopener noreferrer">https://newsroom.tiktok.com/en-us/how-tiktok-recommends-videos-for-you</a></td><td></td></tr><tr><td><a href="https://techcrunch.com/2020/06/18/tiktok-explains-how-the-recommendation-system-behind-its-for-you-feed-works/" target="_blank" rel="noopener noreferrer">https://techcrunch.com/2020/06/18/tiktok-explains-how-the-recommendation-system-behind-its-for-you-feed-works/</a></td><td></td></tr><tr><td>&quot;Reinforcement Learning for Recommender Systems: A Case Study on Youtube,&quot; by Minmin Chen</td><td><a href="https://youtu.be/HEqQ2_1XRTs?list=PLN7ADELDRRhjH-LXON13wyKGN7nDOhcL1" target="_blank" rel="noopener noreferrer">https://youtu.be/HEqQ2_1XRTs?list=PLN7ADELDRRhjH-LXON13wyKGN7nDOhcL1</a></td></tr><tr><td>Top-K Off-Policy Correction for a REINFORCE Recommender System</td><td>AISC</td></tr><tr><td>Contextual Bandits for In-App Recommendation</td><td><a href="https://engineering.nordeus.com/contextual-bandits-for-in-app-recommendation/" target="_blank" rel="noopener noreferrer">https://engineering.nordeus.com/contextual-bandits-for-in-app-recommendation/</a></td></tr><tr><td></td><td><a href="https://arxiv.org/pdf/2011.02260v1.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/2011.02260v1.pdf</a></td></tr><tr><td>RecSys 2020 Keynote: Conversational AI Agents That Can Truly Understand and Help Users</td><td><a href="https://youtu.be/V5xBqcMqT2o?list=PLaZufLfJumb-cVIEsyg4CFocuq4WsvjED" target="_blank" rel="noopener noreferrer">https://youtu.be/V5xBqcMqT2o?list=PLaZufLfJumb-cVIEsyg4CFocuq4WsvjED</a></td></tr><tr><td>RecSys 2020 Tutorial: Conversational Recommender Systems</td><td><a href="https://youtu.be/RdGnJSRA0aw" target="_blank" rel="noopener noreferrer">https://youtu.be/RdGnJSRA0aw</a></td></tr><tr><td>Towards Conversational Recommender Systems</td><td><a href="https://youtu.be/nLUfAJqXFUI" target="_blank" rel="noopener noreferrer">https://youtu.be/nLUfAJqXFUI</a></td></tr><tr><td></td><td><a href="https://arxiv.org/pdf/2004.00646.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/2004.00646.pdf</a></td></tr><tr><td>Yisong Miao</td><td><a href="https://yisong.me/readpapers/convrec/" target="_blank" rel="noopener noreferrer">https://yisong.me/readpapers/convrec/</a></td></tr><tr><td>D√©j√† vu: A Contextualized Temporal Attention Mechanism for Sequential Recommendation</td><td><a href="https://arxiv.org/abs/2002.00741v1" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2002.00741v1</a></td></tr><tr><td>Context-Aware Recommendation Systems</td><td><a href="https://youtu.be/TBg9FSAb8zw" target="_blank" rel="noopener noreferrer">https://youtu.be/TBg9FSAb8zw</a></td></tr><tr><td>AutoML for predictive modeling</td><td><a href="https://towardsdatascience.com/automl-for-predictive-modeling-32b84c5a18f6" target="_blank" rel="noopener noreferrer">https://towardsdatascience.com/automl-for-predictive-modeling-32b84c5a18f6</a></td></tr><tr><td>Multi-task Learning for Recommender Systems</td><td><a href="http://glaros.dtc.umn.edu/gkhome/node/747" target="_blank" rel="noopener noreferrer">http://glaros.dtc.umn.edu/gkhome/node/747</a></td></tr></tbody></table></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/recohut/docs/docs/docs/concept-extras/emerging-concepts-in-recommender-systems.mdx" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_mS5F" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_mt2f"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/docs/concept-extras/diversity"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Diversity</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/docs/concept-extras/graph-embeddings"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Graph Embeddings</div></a></div></nav></div></div><div class="col col--3"><div class="tableOfContents_vrFS thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#real-time-learning-and-inference" class="table-of-contents__link toc-highlight">Real-time Learning and Inference</a><ul><li><a href="#batch-vs-real-time" class="table-of-contents__link toc-highlight">Batch vs. Real-time</a></li><li><a href="#why-real-time-recommendations-then" class="table-of-contents__link toc-highlight"><strong>Why real-time recommendations then?</strong></a></li><li><a href="#example" class="table-of-contents__link toc-highlight">Example</a></li><li><a href="#industry-examples" class="table-of-contents__link toc-highlight">Industry examples</a></li><li><a href="#interesting-reads" class="table-of-contents__link toc-highlight">Interesting reads</a></li></ul></li><li><a href="#contextual-bandits" class="table-of-contents__link toc-highlight">Contextual Bandits</a><ul><li><a href="#online-learning-with-multi-armed-bandits" class="table-of-contents__link toc-highlight">Online learning with multi-armed bandits</a></li><li><a href="#multi-armed-bandit-algorithms-can" class="table-of-contents__link toc-highlight"><strong>Multi-armed bandit algorithms can...</strong></a></li><li><a href="#contextual-bandits-1" class="table-of-contents__link toc-highlight">Contextual bandits</a></li><li><a href="#ab-testing-v-multi-armed-bandits" class="table-of-contents__link toc-highlight">A/B Testing v. Multi-Armed Bandits</a></li><li><a href="#hands-on" class="table-of-contents__link toc-highlight">Hands-on</a></li></ul></li><li><a href="#graphs-networks-and-embeddings" class="table-of-contents__link toc-highlight">Graphs Networks and Embeddings</a><ul><li><a href="#graph-neural-networks" class="table-of-contents__link toc-highlight">Graph Neural Networks</a></li><li><a href="#models" class="table-of-contents__link toc-highlight">Models</a></li><li><a href="#industrial-examples" class="table-of-contents__link toc-highlight">Industrial examples</a></li><li><a href="#hands-on-1" class="table-of-contents__link toc-highlight">Hands-on</a></li></ul></li><li><a href="#conversational-recommenders" class="table-of-contents__link toc-highlight">Conversational Recommenders</a><ul><li><a href="#system-designs" class="table-of-contents__link toc-highlight">System designs</a></li><li><a href="#interesting-reads-1" class="table-of-contents__link toc-highlight">Interesting reads</a></li><li><a href="#hands-on-2" class="table-of-contents__link toc-highlight">Hands-on</a></li></ul></li><li><a href="#context-aware-recommenders" class="table-of-contents__link toc-highlight">Context-aware Recommenders</a><ul><li><a href="#interesting-hands-on" class="table-of-contents__link toc-highlight">Interesting hands-on</a></li></ul></li><li><a href="#automl-approach-to-recommenders" class="table-of-contents__link toc-highlight">AutoML approach to Recommenders</a><ul><li><a href="#hands-on-3" class="table-of-contents__link toc-highlight">Hands-on</a></li></ul></li><li><a href="#multi-task-recommenders" class="table-of-contents__link toc-highlight">Multi-task recommenders</a><ul><li><a href="#multi-task-learning" class="table-of-contents__link toc-highlight">Multi-task learning</a></li><li><a href="#joint-representation-learning" class="table-of-contents__link toc-highlight">Joint Representation Learning</a></li><li><a href="#hands-on-4" class="table-of-contents__link toc-highlight">Hands-on</a></li></ul></li><li><a href="#references" class="table-of-contents__link toc-highlight">References</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Learn</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Introduction</a></li><li class="footer__item"><a href="https://nb.recohut.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Notebooks</a></li><li class="footer__item"><a href="https://step.recohut.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stories</a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/recohut/docs" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright ¬© 2022 Recohut Docs, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.cb8160eb.js"></script>
<script src="/assets/js/main.fedda83c.js"></script>
</body>
</html>